import streamlit as st
import pandas as pd
import asyncio
import aiohttp
import time
import sys
import io
import os
import json
import datetime

# --- è¨­å®šã‚¨ãƒªã‚¢ ---
# åŒæ™‚æ¥ç¶šæ•°ï¼ˆ5ã€œ10æ¨å¥¨ï¼‰
CONCURRENT_REQUESTS = 10 
# 1å›ã«å‡¦ç†ã™ã‚‹ä»¶æ•°ï¼ˆã“ã‚Œã”ã¨ã«ä¼‘æ†©ã™ã‚‹ï¼‰
BATCH_SIZE = 500
# ãƒãƒƒãƒé–“ã®ä¼‘æ†©æ™‚é–“ï¼ˆç§’ï¼‰
BATCH_INTERVAL = 2
# ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ï¼ˆã“ã‚Œã‚’ã€Œä½¿ç”¨ä¸­ã€ã®æœ­ã¨ã—ã¦ä½¿ã†ï¼‰
LOCK_FILE = "system_lock.json"

# Windowsç”¨è¨­å®š
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
}

# --- 1. ãƒ­ãƒƒã‚¯åˆ¶å¾¡ï¼ˆäº¤é€šæ•´ç†ï¼‰ã‚·ã‚¹ãƒ†ãƒ  ---
def get_lock_status():
    """ç¾åœ¨èª°ã‹ãŒä½¿ã£ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã™ã‚‹"""
    if os.path.exists(LOCK_FILE):
        try:
            with open(LOCK_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return True, data
        except:
            return False, None
    return False, None

def acquire_lock(user_name, total_items):
    """ä½¿ç”¨ä¸­æœ­ã‚’æ²ã’ã‚‹"""
    if os.path.exists(LOCK_FILE):
        return False # æ—¢ã«èª°ã‹ãŒä½¿ã£ã¦ã„ã‚‹
    
    start_time = datetime.datetime.now().strftime('%H:%M:%S')
    data = {
        "user": user_name,
        "start_time": start_time,
        "total": total_items,
        "status": "Running"
    }
    with open(LOCK_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False)
    return True

def release_lock():
    """ä½¿ç”¨ä¸­æœ­ã‚’ä¸‹ã‚ã™"""
    if os.path.exists(LOCK_FILE):
        os.remove(LOCK_FILE)

# --- 2. é€šä¿¡ãƒ­ã‚¸ãƒƒã‚¯ ---
async def fetch_single(session, url):
    try:
        async with session.get(url, timeout=20, ssl=False, headers=HEADERS) as response:
            await response.read()
            return {"status": "OK", "code": response.status, "msg": "OK"}
    except asyncio.TimeoutError:
        return {"status": "Error", "code": "Timeout", "msg": "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"}
    except aiohttp.ClientConnectorError:
        return {"status": "Error", "code": "ConnectError", "msg": "æ¥ç¶šä¸å¯"}
    except Exception as e:
        return {"status": "Error", "code": "Error", "msg": str(e)}

async def fetch_url_with_retry(session, url, row_index):
    res = await fetch_single(session, url)
    if res["status"] == "OK":
        return row_index, res["code"], res["msg"]
    
    retry_url = None
    if url.startswith("http:"):
        retry_url = url.replace("http:", "https:", 1)
    elif url.startswith("https:"):
        retry_url = url.replace("https:", "http:", 1)
    
    if retry_url:
        res_retry = await fetch_single(session, retry_url)
        if res_retry["status"] == "OK":
            return row_index, res_retry["code"], f"OK (è‡ªå‹•åˆ‡æ›¿: {retry_url})"
    
    return row_index, res["code"], res["msg"]

async def process_batch(urls, start_index):
    """æŒ‡å®šã•ã‚ŒãŸãƒªã‚¹ãƒˆã®ä¸€éƒ¨ã ã‘ã‚’å‡¦ç†ã™ã‚‹"""
    results = [None] * len(urls)
    messages = [None] * len(urls)
    connector = aiohttp.TCPConnector(limit=CONCURRENT_REQUESTS, ssl=False)
    
    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []
        for i, url in enumerate(urls):
            real_index = start_index + i
            url_str = str(url).strip()
            if url_str.startswith("http"):
                task = fetch_url_with_retry(session, url_str, real_index)
                tasks.append(task)
            else:
                results[i] = "URLä¸æ­£"
                messages[i] = "http/httpsãªã—"

        for task in asyncio.as_completed(tasks):
            # â€»ã“ã“ã§è¿”ã£ã¦ãã‚‹indexã¯å…¨ä½“é€šã—ç•ªå·
            row_index, status_code, msg = await task
            # ãƒãƒƒãƒå†…ã®ç›¸å¯¾ä½ç½®ã«æˆ»ã™
            local_index = row_index - start_index
            results[local_index] = status_code
            messages[local_index] = msg
            
    return results, messages

# --- 3. ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š ---
def highlight_bad_rows(row):
    val = str(row['Status_Code'])
    bad_list = ['ConnectError', 'Timeout', 'URLä¸æ­£', '404', 'Error']
    if val in bad_list:
        return ['background-color: #ffcccc; color: #990000; font-weight: bold'] * len(row)
    return [''] * len(row)

# --- 4. ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.set_page_config(page_title="ãƒãƒ¼ãƒ ç”¨Webãƒã‚§ãƒƒã‚«ãƒ¼", layout="wide")

# ç¾åœ¨ã®çŠ¶æ³ã‚’è¡¨ç¤º
is_locked, lock_info = get_lock_status()

st.title("ğŸš¦ ãƒãƒ¼ãƒ ç”¨ Webã‚µã‚¤ãƒˆç”Ÿå­˜ãƒã‚§ãƒƒã‚«ãƒ¼")

if is_locked:
    st.error(f"â›” ç¾åœ¨ã€ä»–ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒä½¿ç”¨ä¸­ã§ã™ï¼")
    st.info(f"ğŸ‘¤ åˆ©ç”¨è€…: **{lock_info['user']}** ã•ã‚“")
    st.info(f"ğŸ•’ é–‹å§‹æ™‚é–“: {lock_info['start_time']} / ğŸ“¦ ä»¶æ•°: {lock_info['total']} ä»¶")
    st.warning("å‡¦ç†ãŒçµ‚ã‚ã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„ã€‚ç”»é¢ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨çŠ¶æ³ãŒæ›´æ–°ã•ã‚Œã¾ã™ã€‚")
    
    # ä¸‡ãŒä¸€ã®å¼·åˆ¶è§£é™¤ãƒœã‚¿ãƒ³ï¼ˆèª°ã‹ãŒãƒ–ãƒ©ã‚¦ã‚¶é–‰ã˜ã¡ã‚ƒã£ãŸæ™‚ç”¨ï¼‰
    with st.expander("âš ï¸ å‰ã®äººãŒçµ‚ã‚ã£ã¦ã‚‹ã®ã«ãšã£ã¨ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹å ´åˆ"):
        if st.button("å¼·åˆ¶çš„ã«ãƒ­ãƒƒã‚¯ã‚’è§£é™¤ã™ã‚‹"):
            release_lock()
            st.rerun()
            
    # ãƒ­ãƒƒã‚¯ä¸­ã¯ä»¥ä¸‹ã‚’è¡¨ç¤ºã—ãªã„
    st.stop() 

else:
    st.success("âœ… ç¾åœ¨ç©ºã„ã¦ã„ã¾ã™ã€‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")

# --- å…¥åŠ›ã‚¨ãƒªã‚¢ ---
col1, col2 = st.columns([1, 2])
with col1:
    user_name = st.text_input("ã‚ãªãŸã®åå‰", placeholder="ä¾‹: å±±ç”°")
with col2:
    uploaded_file = st.file_uploader("ãƒªã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (æ•°åƒä»¶ã§ã‚‚OK)", type=['xlsx', 'csv'])

if uploaded_file is not None and user_name:
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        st.write(f"ğŸ“‚ èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} ä»¶")
        columns = df.columns.tolist()
        url_col = st.selectbox("URLåˆ—ã‚’é¸æŠ", columns)
        
        if st.button("ğŸš€ ãƒã‚§ãƒƒã‚¯é–‹å§‹"):
            # ãƒ­ãƒƒã‚¯ç²å¾—ã‚’è©¦ã¿ã‚‹
            if not acquire_lock(user_name, len(df)):
                st.error("ã‚¿ãƒƒãƒã®å·®ã§ä»–ã®äººãŒé–‹å§‹ã—ã¾ã—ãŸï¼ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                st.stop()
            
            try:
                # å…¨ãƒ‡ãƒ¼ã‚¿æ•°
                total_rows = len(df)
                all_statuses = [None] * total_rows
                all_msgs = [None] * total_rows
                urls = df[url_col].tolist()
                
                start_time = time.time()
                
                # --- è‡ªå‹•åˆ†å‰²ãƒ«ãƒ¼ãƒ— ---
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # BATCH_SIZE ãšã¤åˆ‡ã‚Šå‡ºã—ã¦å‡¦ç†
                for i in range(0, total_rows, BATCH_SIZE):
                    batch_urls = urls[i : i + BATCH_SIZE]
                    status_text.text(f"å‡¦ç†ä¸­... {i} ï½ {min(i + BATCH_SIZE, total_rows)} ä»¶ç›® / å…¨ {total_rows} ä»¶")
                    
                    # Asyncå‡¦ç†å®Ÿè¡Œ
                    # Windowså¯¾å¿œã®ãƒ«ãƒ¼ãƒ—å–å¾—
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    batch_statuses, batch_msgs = loop.run_until_complete(process_batch(batch_urls, i))
                    loop.close()
                    
                    # çµæœã‚’çµåˆ
                    for j, res in enumerate(batch_statuses):
                        all_statuses[i + j] = res
                        all_msgs[i + j] = batch_msgs[j]
                    
                    # é€²æ—æ›´æ–°
                    progress_bar.progress(min((i + BATCH_SIZE) / total_rows, 1.0))
                    
                    # ä¼‘æ†©ï¼ˆã‚µãƒ¼ãƒãƒ¼ã¸ã®é…æ…®ï¼‰
                    if i + BATCH_SIZE < total_rows:
                        time.sleep(BATCH_INTERVAL)
                
                # --- å®Œäº†å‡¦ç† ---
                df['Status_Code'] = all_statuses
                df['Message'] = all_msgs
                
                end_time = time.time()
                minutes = (end_time - start_time) / 60
                
                st.success(f"âœ… ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸï¼ ({minutes:.1f}åˆ†)")
                
                # è‰²ä»˜ãExcelå‡ºåŠ›
                styler = df.style.apply(highlight_bad_rows, axis=1)
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    styler.to_excel(writer, index=False, sheet_name='Result')
                
                st.download_button(
                    label="ğŸ“¥ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=buffer.getvalue(),
                    file_name=f'check_result_{user_name}.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                )
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            finally:
                # çµ‚ã‚ã£ãŸã‚‰ï¼ˆã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ã§ã‚‚ï¼‰å¿…ãšãƒ­ãƒƒã‚¯è§£é™¤
                release_lock()
                st.info("ãƒ­ãƒƒã‚¯ã‚’è§£é™¤ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
elif uploaded_file is not None and not user_name:
    st.warning("âš ï¸ åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä»–ã®ãƒ¡ãƒ³ãƒãƒ¼ã«é€šçŸ¥ã™ã‚‹ãŸã‚ã§ã™ï¼‰")